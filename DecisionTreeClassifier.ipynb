{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\"\"\"\n",
    "Alternative encoder function for pd.getdummies()\n",
    "\"\"\"\n",
    "def one_hot_encoder(dataf, col):\n",
    "    mapping = {}\n",
    "    working_class = dataf[col].unique();\n",
    "\n",
    "    for i in range(len(working_class)):\n",
    "        mapping[working_class[i]] = i\n",
    "\n",
    "    one_hot_code = []\n",
    "    for w in df[col]:\n",
    "        temp_arr = list(np.zeros(len(mapping), dtype = int))\n",
    "        temp_arr[mapping[w]] = 1\n",
    "        one_hot_code.append(temp_arr)\n",
    "    df[col] = one_hot_code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, gain = 0, y =None, *, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        self.gain = gain\n",
    "        self.y = y\n",
    "        self.count = Counter(y)\n",
    "        self.rule =f\"{feature} <= {round(best_value, 3)}\"\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "\n",
    "    def print_node(self, operator, depth):\n",
    "        preamble0 = f\"|{'---' * 3 * depth}\"\n",
    "        preamble1 = f\"|{'   ' * 3 * depth}   |\"\n",
    "        print(f\"{preamble0} Split rule: {self.labels[self.feature]} {operator} {self.threshold}\")\n",
    "        print(f\"{preamble1} Gain info of the node {round(self.gain, 5)}\")\n",
    "        print(f\"{preamble1} Class distribution in the node {self.count}\")\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=100,  depth=None, n_features=None, criterion = \"GINI\"):\n",
    "        self.labels = None\n",
    "        self.min_samples_splits = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features= n_features\n",
    "        self.root = None\n",
    "        self.depth = depth if depth else 0\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Number of features do not exceed the actua feature we have\n",
    "        self.n_features = X.shape[1] if not self.n_features else min(X.shape[1], self.n_features)\n",
    "        self.labels = X.columns\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_feats = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        # check the stopping criteria\n",
    "        if depth>=self.max_depth or n_labels == 1 or n_samples<self.min_samples_splits:\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        feat_idxs = np.random.choice(n_feats, self.n_features, replace=False)\n",
    "        # find the best split\n",
    "        best_feature, best_thresh, gain, y_0 = self._best_split(X, y, feat_idxs)\n",
    "\n",
    "        # create child nodes\n",
    "        left_idxs, right_idxs = self._split(X.iloc[:, best_feature], best_thresh)\n",
    "        left = self._grow_tree(X.iloc[left_idxs, :], y.iloc[left_idxs], depth + 1)\n",
    "        right = self._grow_tree(X.iloc[right_idxs, :], y.iloc[right_idxs], depth + 1)\n",
    "        return Node(best_feature, best_thresh, left, right, gain, y_0)\n",
    "\n",
    "    def _best_split(self, X, y, feat_idxs):\n",
    "        # initialize best_gain and gini_index\n",
    "        best_gain = -1\n",
    "        split_idx, split_threshold = None, None\n",
    "\n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X.iloc[:, feat_idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "\n",
    "            for thr in thresholds:\n",
    "                if self.criterion == \"GINI\":\n",
    "                    # calculate the GINI gain\n",
    "                    gain = self.GINI_gain(y, X_column, thr)\n",
    "                elif self.criterion == \"GAIN_RATIO\":\n",
    "                    gain = self._gain_ratio(y, X_column, thr)\n",
    "                else:\n",
    "                    # calculate the information gain\n",
    "                    gain = self._information_gain(y, X_column, thr)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_threshold = thr\n",
    "        return split_idx, split_threshold, best_gain, y\n",
    "\n",
    "    def GINI_gain(self, y, X_column, threshold):\n",
    "        GINI_base = self.get_GINI(y)\n",
    "\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "        left_counts = Counter(y.iloc[left_idxs])\n",
    "        right_counts = Counter(y.iloc[right_idxs])\n",
    "\n",
    "        y0_left, y1_left, y0_right, y1_right = Counter(left_counts).get(0,0),Counter(left_counts).get(0,1), \\\n",
    "                                               Counter(right_counts).get(0,0), Counter(right_counts).get(0,1)\n",
    "\n",
    "        gini_left = self.GINI_impurity(y0_left, y1_left)\n",
    "        gini_right = self.GINI_impurity(y0_right, y1_right)\n",
    "\n",
    "        # Getting the obs count from the left and the right data splits\n",
    "        n_left = y0_left + y1_left\n",
    "        n_right = y0_right + y1_right\n",
    "\n",
    "        # Calculating the weights for each of the nodes\n",
    "        w_left = n_left / (n_left + n_right)\n",
    "        w_right = n_right / (n_left + n_right)\n",
    "\n",
    "        #Calculate the GINI impurity\n",
    "        wGINI = w_left * gini_left + w_right * gini_right\n",
    "\n",
    "        #Calculate GINI gain\n",
    "        GINI_gain = GINI_base - wGINI\n",
    "        return GINI_gain\n",
    "\n",
    "    def get_GINI(self, y):\n",
    "        \"\"\"\n",
    "        Calculate the GINI impurity of a node\n",
    "        \"\"\"\n",
    "        y1_count, y2_count = Counter(y).get(0, 0), Counter(y).get(1, 0)\n",
    "        return self.GINI_impurity(y1_count, y2_count)\n",
    "\n",
    "    def GINI_impurity(self, y1_count, y2_count):\n",
    "        if y1_count is None:\n",
    "            y1_count = 0\n",
    "        if y2_count is None:\n",
    "            y2_count = 0\n",
    "        n = y1_count + y2_count\n",
    "        # If n is 0 then we return the lowest possible gini impurity\n",
    "        if n == 0:\n",
    "            return 0\n",
    "        p1 = y1_count/n\n",
    "        p2 = y2_count/n\n",
    "        gini = 1 - (p1**2 + p2**2)\n",
    "        return gini\n",
    "\n",
    "    def _gain_ratio(self, y, X_column, threshold):\n",
    "        # parent entropy\n",
    "        parent_entropy = self._entropy(y)\n",
    "        # create children\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "\n",
    "        # calculate the weighted entropy of children\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = self._entropy(y.iloc[left_idxs]), self._entropy(y.iloc[right_idxs])\n",
    "        child_entropy = (n_l/n) * e_l + (n_r/n) * e_r\n",
    "\n",
    "        # calculate the IG\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "\n",
    "        split_info = -(n_l/n * np.log(n_l/n) +  n_r/n * np.log(n_r/n))\n",
    "\n",
    "        return information_gain / split_info\n",
    "\n",
    "    def _information_gain(self, y, X_column, threshold):\n",
    "        # parent entropy\n",
    "        parent_entropy = self._entropy(y)\n",
    "        # create children\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "\n",
    "        # calculate the weighted entropy of children\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = self._entropy(y.iloc[left_idxs]), self._entropy(y.iloc[right_idxs])\n",
    "        child_entropy = (n_l/n) * e_l + (n_r/n) * e_r\n",
    "\n",
    "        # calculate the IG\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain\n",
    "\n",
    "    def _split(self, X_column, split_thresh):\n",
    "        left_idxs = np.argwhere(X_column.to_numpy() <= split_thresh).flatten()\n",
    "        right_idxs = np.argwhere(X_column.to_numpy() > split_thresh).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist / len(y)\n",
    "        return -np.sum([p * np.log(p) for p in ps if p>0])\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        if len(Counter(y).most_common(1)) == 0:\n",
    "            value = None\n",
    "        else:\n",
    "            value = counter.most_common(1)[0][0]\n",
    "        return value\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for idx, x in X.iterrows()])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold :\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "\n",
    "    def print_info(self, node, depth):\n",
    "        \"\"\"\n",
    "        Method to print the information about the tree\n",
    "        \"\"\"\n",
    "        node.print_node\n",
    "\n",
    "        self.print_info(node.left, '<=', depth + 1)\n",
    "\n",
    "        #\n",
    "        # print(f\"{preamble0} Split rule: {self.labels[node.feature]} <= {node.threshold}\")\n",
    "        # print(f\"{preamble1} Gain info the node {round(node.gain, 5)}\")\n",
    "        # print(f\"{preamble1} Class distribution in the node {node.count}\")\n",
    "        # # print(f\"{preamble1} Predicted class {node.predict}\")\n",
    "\n",
    "        self.print_info(node.right, '>', depth + 1)\n",
    "\n",
    "\n",
    "        # print(f\"{preamble0} Split rule: {self.labels[node.feature]} > {node.threshold}\")\n",
    "        # print(f\"{preamble1} Gain info of the node {round(node.gain, 5)}\")\n",
    "        # print(f\"{preamble1} Class distribution in the node {node.count}\")\n",
    "\n",
    "\n",
    "\n",
    "    def print_tree(self):\n",
    "        \"\"\"\n",
    "        Prints the whole tree from the current node to the bottom\n",
    "        \"\"\"\n",
    "        if self.root.is_leaf_node():\n",
    "            return\n",
    "\n",
    "        self.print_info(self.root, 1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, gain = 0, y =None, *, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        self.gain = gain\n",
    "        self.y = y\n",
    "        self.count = Counter(y)\n",
    "        # self.rule =f\"{feature} <= {round(best_value, 3)}\"\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "\n",
    "    # def print_node(self, operator, depth):\n",
    "    #     preamble0 = f\"|{'---' * 3 * depth}\"\n",
    "    #     preamble1 = f\"|{'   ' * 3 * depth}   |\"\n",
    "    #     print(f\"{preamble0} Split rule: {self.labels[self.feature]} {operator} {self.threshold}\")\n",
    "    #     print(f\"{preamble1} Gain info of the node {round(self.gain, 5)}\")\n",
    "    #     print(f\"{preamble1} Class distribution in the node {self.count}\")\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=100,  depth=None, n_features=None, criterion = \"GINI\"):\n",
    "        self.labels = None\n",
    "        self.min_samples_splits = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features= n_features\n",
    "        self.root = None\n",
    "        self.depth = depth if depth else 0\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Number of features do not exceed the actua feature we have\n",
    "        self.n_features = X.shape[1] if not self.n_features else min(X.shape[1], self.n_features)\n",
    "        self.labels = X.columns\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_feats = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        # check the stopping criteria\n",
    "        if depth>=self.max_depth or n_labels == 1 or n_samples<self.min_samples_splits:\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        feat_idxs = np.random.choice(n_feats, self.n_features, replace=False)\n",
    "        # find the best split\n",
    "        best_feature, best_thresh, gain, y_0 = self._best_split(X, y, feat_idxs)\n",
    "\n",
    "        # create child nodes\n",
    "        left_idxs, right_idxs = self._split(X.iloc[:, best_feature], best_thresh)\n",
    "        left = self._grow_tree(X.iloc[left_idxs, :], y.iloc[left_idxs], depth + 1)\n",
    "        right = self._grow_tree(X.iloc[right_idxs, :], y.iloc[right_idxs], depth + 1)\n",
    "        return Node(best_feature, best_thresh, left, right, gain, y_0)\n",
    "\n",
    "    def _best_split(self, X, y, feat_idxs):\n",
    "        # initialize best_gain and gini_index\n",
    "        best_gain = -1\n",
    "        split_idx, split_threshold = None, None\n",
    "\n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X.iloc[:, feat_idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "\n",
    "            for thr in thresholds:\n",
    "                if self.criterion == \"GINI\":\n",
    "                    # calculate the GINI gain\n",
    "                    gain = self.GINI_gain(y, X_column, thr)\n",
    "                elif self.criterion == \"GAIN_RATIO\":\n",
    "                    gain = self._gain_ratio(y, X_column, thr)\n",
    "                else:\n",
    "                    # calculate the information gain\n",
    "                    gain = self._information_gain(y, X_column, thr)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_threshold = thr\n",
    "        return split_idx, split_threshold, best_gain, y\n",
    "\n",
    "    def GINI_gain(self, y, X_column, threshold):\n",
    "        GINI_base = self.get_GINI(y)\n",
    "\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "        left_counts = Counter(y.iloc[left_idxs])\n",
    "        right_counts = Counter(y.iloc[right_idxs])\n",
    "\n",
    "        y0_left, y1_left, y0_right, y1_right = Counter(left_counts).get(0,0),Counter(left_counts).get(0,1), \\\n",
    "            Counter(right_counts).get(0,0), Counter(right_counts).get(0,1)\n",
    "\n",
    "        gini_left = self.GINI_impurity(y0_left, y1_left)\n",
    "        gini_right = self.GINI_impurity(y0_right, y1_right)\n",
    "\n",
    "        # Getting the obs count from the left and the right data splits\n",
    "        n_left = y0_left + y1_left\n",
    "        n_right = y0_right + y1_right\n",
    "\n",
    "        # Calculating the weights for each of the nodes\n",
    "        w_left = n_left / (n_left + n_right)\n",
    "        w_right = n_right / (n_left + n_right)\n",
    "\n",
    "        #Calculate the GINI impurity\n",
    "        wGINI = w_left * gini_left + w_right * gini_right\n",
    "\n",
    "        #Calculate GINI gain\n",
    "        GINI_gain = GINI_base - wGINI\n",
    "        return GINI_gain\n",
    "\n",
    "    def get_GINI(self, y):\n",
    "        \"\"\"\n",
    "        Calculate the GINI impurity of a node\n",
    "        \"\"\"\n",
    "        y1_count, y2_count = Counter(y).get(0, 0), Counter(y).get(1, 0)\n",
    "        return self.GINI_impurity(y1_count, y2_count)\n",
    "\n",
    "    def GINI_impurity(self, y1_count, y2_count):\n",
    "        if y1_count is None:\n",
    "            y1_count = 0\n",
    "        if y2_count is None:\n",
    "            y2_count = 0\n",
    "        n = y1_count + y2_count\n",
    "        # If n is 0 then we return the lowest possible gini impurity\n",
    "        if n == 0:\n",
    "            return 0\n",
    "        p1 = y1_count/n\n",
    "        p2 = y2_count/n\n",
    "        gini = 1 - (p1**2 + p2**2)\n",
    "        return gini\n",
    "\n",
    "    def _gain_ratio(self, y, X_column, threshold):\n",
    "        # parent entropy\n",
    "        parent_entropy = self._entropy(y)\n",
    "        # create children\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "\n",
    "        # calculate the weighted entropy of children\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = self._entropy(y.iloc[left_idxs]), self._entropy(y.iloc[right_idxs])\n",
    "        child_entropy = (n_l/n) * e_l + (n_r/n) * e_r\n",
    "\n",
    "        # calculate the IG\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "\n",
    "        split_info = -(n_l/n * np.log(n_l/n) +  n_r/n * np.log(n_r/n))\n",
    "\n",
    "        return information_gain / split_info\n",
    "\n",
    "    def _information_gain(self, y, X_column, threshold):\n",
    "        # parent entropy\n",
    "        parent_entropy = self._entropy(y)\n",
    "        # create children\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "\n",
    "        # calculate the weighted entropy of children\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = self._entropy(y.iloc[left_idxs]), self._entropy(y.iloc[right_idxs])\n",
    "        child_entropy = (n_l/n) * e_l + (n_r/n) * e_r\n",
    "\n",
    "        # calculate the IG\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain\n",
    "\n",
    "    def _split(self, X_column, split_thresh):\n",
    "        left_idxs = np.argwhere(X_column.to_numpy() <= split_thresh).flatten()\n",
    "        right_idxs = np.argwhere(X_column.to_numpy() > split_thresh).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist / len(y)\n",
    "        return -np.sum([p * np.log(p) for p in ps if p>0])\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        if len(Counter(y).most_common(1)) == 0:\n",
    "            value = None\n",
    "        else:\n",
    "            value = counter.most_common(1)[0][0]\n",
    "        return value\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for idx, x in X.iterrows()])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold :\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "\n",
    "    def print_info(self, node, depth):\n",
    "        \"\"\"\n",
    "        Method to print the information about the tree\n",
    "        \"\"\"\n",
    "        if node.feature is None:\n",
    "            return\n",
    "\n",
    "        preamble0 = f\"|{'---' * 3 * depth}\"\n",
    "        preamble1 = f\"|{'   ' * 3 * depth}   |\"\n",
    "\n",
    "        print(f\"{preamble0} Split rule: {self.labels[node.feature]} <= {node.threshold}\")\n",
    "        print(f\"{preamble1} Gain info the node {round(node.left.gain, 5)}\")\n",
    "        print(f\"{preamble1} Class distribution in the node {node.left.count}\")\n",
    "        # print(f\"{preamble1} Predicted class {node.predict}\")\n",
    "\n",
    "        self.print_info(node.left, depth + 1)\n",
    "\n",
    "        print(f\"{preamble0} Split rule: {self.labels[node.feature]} > {node.threshold}\")\n",
    "        print(f\"{preamble1} Gain info of the node {round(node.right.gain, 5)}\")\n",
    "        print(f\"{preamble1} Class distribution in the node {node.right.count}\")\n",
    "        # print(f\"{preamble1} Predicted class {node.predict}\")\n",
    "\n",
    "        self.print_info(node.right, depth + 1)\n",
    "\n",
    "    def print_tree(self):\n",
    "        \"\"\"\n",
    "        Prints the whole tree from the current node to the bottom\n",
    "        \"\"\"\n",
    "        if self.root.is_leaf_node():\n",
    "            return\n",
    "        else:\n",
    "            self.print_info(self.root, 1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root\n",
      "|--------- Split rule: education-num <= 12\n",
      "|            | Gain info the node 0.10371\n",
      "|            | Class distribution in the node Counter({1: 36, 0: 5})\n",
      "|------------------ Split rule: age <= 36\n",
      "|                     | Gain info the node 0\n",
      "|                     | Class distribution in the node Counter()\n",
      "|------------------ Split rule: age > 36\n",
      "|                     | Gain info of the node 0.14794\n",
      "|                     | Class distribution in the node Counter({1: 14, 0: 5})\n",
      "|--------------------------- Split rule: fnlwgt <= 249977\n",
      "|                              | Gain info the node 0.26537\n",
      "|                              | Class distribution in the node Counter({1: 13, 0: 2})\n",
      "|------------------------------------ Split rule:  Some-college <= 0\n",
      "|                                       | Gain info the node 0\n",
      "|                                       | Class distribution in the node Counter()\n",
      "|------------------------------------ Split rule:  Some-college > 0\n",
      "|                                       | Gain info of the node 0\n",
      "|                                       | Class distribution in the node Counter()\n",
      "|--------------------------- Split rule: fnlwgt > 249977\n",
      "|                              | Gain info of the node 0.56234\n",
      "|                              | Class distribution in the node Counter({0: 3, 1: 1})\n",
      "|------------------------------------ Split rule:  Unmarried <= 0\n",
      "|                                       | Gain info the node 0\n",
      "|                                       | Class distribution in the node Counter()\n",
      "|------------------------------------ Split rule:  Unmarried > 0\n",
      "|                                       | Gain info of the node 0\n",
      "|                                       | Class distribution in the node Counter()\n",
      "|--------- Split rule: education-num > 12\n",
      "|            | Gain info of the node 0.18588\n",
      "|            | Class distribution in the node Counter({0: 12, 1: 7})\n",
      "|------------------ Split rule:  Private <= 0\n",
      "|                     | Gain info the node 0\n",
      "|                     | Class distribution in the node Counter()\n",
      "|------------------ Split rule:  Private > 0\n",
      "|                     | Gain info of the node 0.34413\n",
      "|                     | Class distribution in the node Counter({1: 7, 0: 6})\n",
      "|--------------------------- Split rule: fnlwgt <= 193524\n",
      "|                              | Gain info the node 0.56234\n",
      "|                              | Class distribution in the node Counter({0: 6, 1: 2})\n",
      "|------------------------------------ Split rule: age <= 30\n",
      "|                                       | Gain info the node 0\n",
      "|                                       | Class distribution in the node Counter()\n",
      "|------------------------------------ Split rule: age > 30\n",
      "|                                       | Gain info of the node 0\n",
      "|                                       | Class distribution in the node Counter()\n",
      "|--------------------------- Split rule: fnlwgt > 193524\n",
      "|                              | Gain info of the node 0\n",
      "|                              | Class distribution in the node Counter()\n",
      "0.9833333333333333 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('adult.data', nrows = 100)\n",
    "columns_names = ['age', 'workclass', 'fnlwgt',\n",
    "                 'education', 'education-num', 'marital-status', 'occupation',\n",
    "                 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
    "                 'hours-per-week', 'native-country', 'income']\n",
    "df.columns = columns_names\n",
    "for col in columns_names[:-1]:\n",
    "    if isinstance(df[col][0], str):\n",
    "        df[col] = df[col].astype(\"category\")\n",
    "\n",
    "\"\"\"\n",
    "    Preprocessing dataframe by encoding categorical data type column into 0 and 1\n",
    "\"\"\"\n",
    "data = pd.DataFrame()\n",
    "for col in columns_names[:-1]:\n",
    "    if df[col].dtype == \"category\":\n",
    "        # print(df[col])\n",
    "        one_hot = pd.get_dummies(df[col])\n",
    "        # df.drop(columns = col)\n",
    "        for c in one_hot.columns:\n",
    "            data[c] = one_hot[c]\n",
    "    else:\n",
    "        data[col] = df[col]\n",
    "data['income'] = df['income']\n",
    "data.income.replace((' <=50K', ' >50K'), (1, 0), inplace=True)\n",
    "\n",
    "# Attributes of class income to split\n",
    "X = data[data.columns[:-1]]\n",
    "# Class income\n",
    "y = data['income']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=41347\n",
    ")\n",
    "\n",
    "labels = X_train.columns\n",
    "clf = DecisionTree(max_depth=4, criterion=\"info\")\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "predictions_tr = clf.predict(X_train)\n",
    "\n",
    "print(\"Root\")\n",
    "clf.print_tree()\n",
    "\n",
    "# Check accuracy of the Decision Tree\n",
    "def accuracy(y_test, y_pred):\n",
    "    return np.sum(y_test == y_pred) / len(y_test)\n",
    "acc = accuracy(y_test, predictions)\n",
    "\n",
    "acc_train = accuracy(y_train, predictions_tr)\n",
    "print(acc_train, acc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
